{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-02T21:21:51.251994Z",
     "start_time": "2025-12-02T21:21:50.617371Z"
    }
   },
   "source": [
    "print (\"In the following you will find my workings on a text corpus while using SpaCy and Tracery to build a text generator out of it.\")\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "text = open(\"../week4/test_text\").read()\n",
    "doc = nlp(text)\n",
    "\n",
    "print (\"\")\n",
    "print (\"---------------------\")\n",
    "print (\"\")\n",
    "\n",
    "from spacy import displacy\n",
    "doc_demo = nlp('I Have a Dream is a Speech by the Rev. Martin Luther King Jr. at the March on Washington')\n",
    "displacy.render(doc_demo, style=\"ent\")\n",
    "\n",
    "print (\"\")\n",
    "print (\"---------------------\")\n",
    "print (\"\")\n",
    "\n",
    "print (\"Background Information:\")\n",
    "\n",
    "sentences = list(doc.sents)\n",
    "print(\"1) There are in total of\", len(sentences), \"sentences in the text corpus.\")\n",
    "\n",
    "print (\"2) The top 10 most common words with exact count ->\")\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "all_words =  [token for token in doc if token.is_alpha]\n",
    "word_count = Counter([w.text for w in all_words])\n",
    "\n",
    "print(word_count.most_common(10))\n",
    "\n",
    "print (\"\")\n",
    "print (\"---------------------\")\n",
    "print (\"\")\n",
    "\n",
    "print (\"With enough Background Information, now the final Text Generator is ready for use:\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the following you will find my workings on a text corpus while using SpaCy and Tracery to build a text generator out of it.\n",
      "\n",
      "---------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I Have a Dream is a Speech by the Rev. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Martin Luther King Jr.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " at the \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    March\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Washington\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------\n",
      "\n",
      "Background Information:\n",
      "1) There are in total of 55 sentences in the text corpus.\n",
      "2) The top 10 most common words with exact count ->\n",
      "[('the', 58), ('of', 55), ('a', 27), ('and', 24), ('to', 22), ('be', 18), ('in', 17), ('as', 17), ('will', 13), ('freedom', 13)]\n",
      "\n",
      "---------------------\n",
      "\n",
      "With enough Background Information, now the final Text Generator is ready for use:\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T21:24:21.161464Z",
     "start_time": "2025-12-02T21:24:21.006465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english\n",
    "\n",
    "text = open(\"../week4/test_text\").read()\n",
    "doc = nlp(text)\n",
    "all_words = [token for token in doc if token.is_alpha]\n",
    "\n",
    "NOUNs = [token.lemma_ for token in all_words if token.pos_ == \"NOUN\"]\n",
    "VERBs = [token.lemma_ for token in all_words if token.pos_ == \"VERB\"]\n",
    "ADJs  = [token.lemma_ for token in all_words if token.pos_ == \"ADJ\"]\n",
    "ADVs  = [token.lemma_ for token in all_words if token.pos_ == \"ADV\"]\n",
    "PRONs = [token.lemma_ for token in all_words if token.pos_ == \"PRON\"]\n",
    "ADPs  = [token.lemma_ for token in all_words if token.pos_ == \"ADP\"]\n",
    "DETs  = [token.lemma_ for token in all_words if token.pos_ == \"DET\"]\n",
    "AUXs  = [token.lemma_ for token in all_words if token.pos_ == \"AUX\"]\n",
    "\n",
    "# The idea was to have different sentence structures for the generator, as well as capitalizing Nouns same as the start of each sentence and ending with a period at the end of each sentence.\n",
    "\n",
    "# Probably it does not generate the most meaningful sentences but it was somehow interesting thinking about all the aspects that need to be taken into account while creating a text corpus based generator.\n",
    "\n",
    "rules = {\n",
    "    \"origin\": [\"#sentence_type_1#\", \"#sentence_type_2#\", \"#sentence_type_3#\", \"#sentence_type_4#\", \"#sentence_type_5#\"],\n",
    "    \"sentence_type_1\": \"#Article.capitalize# #Noun.capitalize# #Verb# #Article# #Noun.capitalize#.\",\n",
    "    \"sentence_type_2\": \"#Article.capitalize# #Noun.capitalize# #Verb# #Preposition# #Article# #Noun.capitalize#.\",\n",
    "    \"sentence_type_3\": \"#Pronoun.capitalize# #AuxVerb# #Adverb# #Verb# #Article# #Noun.capitalize#.\",\n",
    "    \"sentence_type_4\": \"#Article.capitalize# #Noun.capitalize# #Verb# #Article# #Noun.capitalize# #Preposition# #Article# #Noun.capitalize#.\",\n",
    "    \"sentence_type_5\": \"#Pronoun.capitalize# #AuxVerb# #Article# #Adjective# #Noun.capitalize# #Verb#.\",\n",
    "    \"Noun\": NOUNs,\n",
    "    \"Verb\": VERBs,\n",
    "    \"Adjective\": ADJs,\n",
    "    \"Adverb\": ADVs,\n",
    "    \"Pronoun\": PRONs,\n",
    "    \"Preposition\": ADPs,\n",
    "    \"Article\": DETs,\n",
    "    \"AuxVerb\": AUXs\n",
    "}\n",
    "\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "\n",
    "for i in range(10):\n",
    "    print(grammar.flatten(\"#origin#\"))\n",
    "\n"
   ],
   "id": "869c33fe5e352084",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You be long allow a Freedom.\n",
      "The Dream guarantee a Body.\n",
      "The Freedom rise by the Justice.\n",
      "We be long let a Hilltop.\n",
      "We must later come every Self.\n",
      "The Fatigue allow a Midst.\n",
      "Our can a civil Freedom have.\n",
      "We must a magnificent Year state.\n",
      "The Discipline let the Adulthood with the Hamlet.\n",
      "Their can the white Dream fall.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Reflection: Maybe another text corpus and other sentence-types (structure) would be more fitting for the task.",
   "id": "b2794e7b5dc30019"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
